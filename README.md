# seq2seq_transformer_translation
Seq2Seq model for German to English translation using a simple transformer architecture. 

Uses [Multi30k](https://www.statmt.org/wmt16/multimodal-task.html#task1) dataset to train a German to English translation model. 

The transformer architecture was first introducted in ["Attention is all you need"](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)


